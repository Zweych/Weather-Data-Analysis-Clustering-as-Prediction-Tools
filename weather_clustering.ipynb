{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library yang akan dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset dan melihat detail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Tn</th>\n",
       "      <th>Tx</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>RH_avg</th>\n",
       "      <th>RR</th>\n",
       "      <th>ss</th>\n",
       "      <th>ff_x</th>\n",
       "      <th>ddd_x</th>\n",
       "      <th>ff_avg</th>\n",
       "      <th>ddd_car</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>96733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>W</td>\n",
       "      <td>96733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>W</td>\n",
       "      <td>96733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>W</td>\n",
       "      <td>96733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>27.8</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>96733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    Tn    Tx  Tavg  RH_avg    RR   ss  ff_x  ddd_x  ff_avg  \\\n",
       "0  2018-01-01  24.0  34.0  28.1    80.0  21.3  8.0   6.0  240.0     5.0   \n",
       "1  2018-01-02  24.0  34.0  29.7    75.0   NaN  6.9   5.0  250.0     6.0   \n",
       "2  2018-01-03  26.0  34.8  28.3    78.0   NaN  4.3   5.0  280.0     7.0   \n",
       "3  2018-01-04  26.0  33.8  29.0    76.0   NaN  4.8   5.0  230.0     6.0   \n",
       "4  2018-01-05  26.0  30.8  27.8    72.0   0.3  1.8   7.0  250.0    10.0   \n",
       "\n",
       "  ddd_car  station_id  \n",
       "0       W       96733  \n",
       "1       W       96733  \n",
       "2       W       96733  \n",
       "3       W       96733  \n",
       "4       W       96733  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "# station_id = 96735\n",
    "# df = df[df['station_id'] == station_id]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tn</th>\n",
       "      <th>Tx</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>RH_avg</th>\n",
       "      <th>RR</th>\n",
       "      <th>ss</th>\n",
       "      <th>ff_x</th>\n",
       "      <th>ddd_x</th>\n",
       "      <th>ff_avg</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31374.000000</td>\n",
       "      <td>31601.000000</td>\n",
       "      <td>31075.000000</td>\n",
       "      <td>31054.000000</td>\n",
       "      <td>24109.000000</td>\n",
       "      <td>28827.000000</td>\n",
       "      <td>32543.000000</td>\n",
       "      <td>32536.000000</td>\n",
       "      <td>32543.000000</td>\n",
       "      <td>32564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.366568</td>\n",
       "      <td>31.586504</td>\n",
       "      <td>27.009445</td>\n",
       "      <td>78.817254</td>\n",
       "      <td>7.610610</td>\n",
       "      <td>6.177032</td>\n",
       "      <td>4.641705</td>\n",
       "      <td>181.797855</td>\n",
       "      <td>1.903482</td>\n",
       "      <td>96845.308807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.736772</td>\n",
       "      <td>3.823300</td>\n",
       "      <td>2.279563</td>\n",
       "      <td>43.034775</td>\n",
       "      <td>16.558978</td>\n",
       "      <td>5.157914</td>\n",
       "      <td>2.091569</td>\n",
       "      <td>106.710820</td>\n",
       "      <td>1.120372</td>\n",
       "      <td>86.203201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96753.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96835.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>7520.000000</td>\n",
       "      <td>277.500000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>96987.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tn            Tx          Tavg        RH_avg            RR  \\\n",
       "count  31374.000000  31601.000000  31075.000000  31054.000000  24109.000000   \n",
       "mean      23.366568     31.586504     27.009445     78.817254      7.610610   \n",
       "std        2.736772      3.823300      2.279563     43.034775     16.558978   \n",
       "min        2.400000      3.600000     17.900000     34.000000      0.000000   \n",
       "25%       22.000000     30.200000     26.000000     73.000000      0.000000   \n",
       "50%       24.000000     32.000000     27.500000     79.000000      0.000000   \n",
       "75%       25.000000     33.200000     28.600000     84.000000      7.000000   \n",
       "max       36.000000    334.000000     34.300000   7520.000000    277.500000   \n",
       "\n",
       "                 ss          ff_x         ddd_x        ff_avg    station_id  \n",
       "count  28827.000000  32543.000000  32536.000000  32543.000000  32564.000000  \n",
       "mean       6.177032      4.641705    181.797855      1.903482  96845.308807  \n",
       "std        5.157914      2.091569    106.710820      1.120372     86.203201  \n",
       "min        0.000000      0.000000      0.000000      0.000000  96733.000000  \n",
       "25%        4.000000      3.000000     90.000000      1.000000  96753.000000  \n",
       "50%        6.600000      4.000000    170.000000      2.000000  96835.000000  \n",
       "75%        8.600000      6.000000    280.000000      2.000000  96937.000000  \n",
       "max      705.000000     26.000000    360.000000     11.000000  96987.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32564 entries, 0 to 32563\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        32564 non-null  object \n",
      " 1   Tn          31374 non-null  float64\n",
      " 2   Tx          31601 non-null  float64\n",
      " 3   Tavg        31075 non-null  float64\n",
      " 4   RH_avg      31054 non-null  float64\n",
      " 5   RR          24109 non-null  float64\n",
      " 6   ss          28827 non-null  float64\n",
      " 7   ff_x        32543 non-null  float64\n",
      " 8   ddd_x       32536 non-null  float64\n",
      " 9   ff_avg      32543 non-null  float64\n",
      " 10  ddd_car     32564 non-null  object \n",
      " 11  station_id  32564 non-null  int64  \n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "Tn            1190\n",
       "Tx             963\n",
       "Tavg          1489\n",
       "RH_avg        1510\n",
       "RR            8455\n",
       "ss            3737\n",
       "ff_x            21\n",
       "ddd_x           28\n",
       "ff_avg          21\n",
       "ddd_car          0\n",
       "station_id       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengisi data kosong yang ada di dalam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_groupby_mean(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('station_id')[column].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "\n",
    "def fillna_groupby_mode(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('station_id')[column].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "\n",
    "fillna_groupby_mean(df, ['Tn', 'Tx', 'Tavg', 'RH_avg', 'RR', 'ss', 'ff_x', 'ddd_x', 'ff_avg'])\n",
    "fillna_groupby_mode(df, ['ddd_car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "Tn               0\n",
       "Tx               0\n",
       "Tavg             0\n",
       "RH_avg        1067\n",
       "RR               0\n",
       "ss            1409\n",
       "ff_x             0\n",
       "ddd_x            0\n",
       "ff_avg           0\n",
       "ddd_car          0\n",
       "station_id       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena masih ada data kosong detelah diisi, dataset kosong sisanya akan dihapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode / merubah tipe data object menjadi data numerik menggunakan label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['ddd_car']= label_encoder.fit_transform(df['ddd_car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengecek apakah ada outlier / tidak pada sebaran data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers in Tn: 1258\n",
      "Number of Outliers in Tx: 1053\n",
      "Number of Outliers in Tavg: 1290\n",
      "Number of Outliers in RH_avg: 253\n",
      "Number of Outliers in RR: 2218\n",
      "Number of Outliers in ss: 6\n",
      "Number of Outliers in ff_x: 375\n",
      "Number of Outliers in ddd_x: 0\n",
      "Number of Outliers in ff_avg: 1923\n",
      "Number of Outliers in ddd_car: 0\n",
      "Number of Outliers in station_id: 0\n"
     ]
    }
   ],
   "source": [
    "def check_outlier(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "\n",
    "    outliers = df[(df < (Q1-1.5*IQR)) | (df > (Q3+1.5*IQR))]\n",
    "    return outliers\n",
    "\n",
    "def print_outlier(df):\n",
    "    for i in df.columns:\n",
    "        if i not in ['date']:\n",
    "            print(f\"Number of Outliers in {i}: {len(check_outlier(df[i]))}\")\n",
    "\n",
    "print_outlier(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghapus outlier pada sebaran data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Tn has been handled\n",
      "Column Tx has been handled\n",
      "Column Tavg has been handled\n",
      "Column RH_avg has been handled\n",
      "Column RR has been handled\n",
      "Column ss has been handled\n",
      "Column ff_x has been handled\n",
      "Column ddd_x has been handled\n",
      "Column ff_avg has been handled\n",
      "Column ddd_car has been handled\n",
      "Column station_id has been handled\n",
      "It is Done!\n"
     ]
    }
   ],
   "source": [
    "def handle_outlier(df):\n",
    "    for i in df.columns:\n",
    "        if i not in ['date']:\n",
    "            Q1 = df[i].quantile(0.25)\n",
    "            Q3 = df[i].quantile(0.75)\n",
    "            IQR = Q3-Q1\n",
    "\n",
    "            lower_bound = Q1 - 1.5*IQR\n",
    "            upper_bound = Q3 + 1.5*IQR\n",
    "\n",
    "            df[i] = np.where(df[i] < lower_bound, lower_bound, df[i])\n",
    "            df[i] = np.where(df[i] > upper_bound, upper_bound, df[i])\n",
    "\n",
    "            print(f'Column {i} has been handled')\n",
    "    print('It is Done!')\n",
    "\n",
    "handle_outlier(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memilih fitur yang akan digunakan oleh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Tn', 'Tx', 'Tavg', 'RH_avg', 'RR', \n",
    "            'ss', 'ff_x', 'ddd_x', 'ff_avg', 'ddd_car']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan normalisasi menggunakan standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan reduksi dimensi pada data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mencari jumlah n cluster optimal menggunakan elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rave\\AppData\\Local\\Temp\\ipykernel_27024\\697528764.py:20: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def optimise_k_means(df, max_k):\n",
    "    means = []\n",
    "    inertias = []\n",
    "    \n",
    "    for k in range(1, max_k):\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(df)\n",
    "        \n",
    "        means.append(k)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        \n",
    "    fig = plt.subplots(figsize=(10,5))\n",
    "    plt.plot(means, inertias, 'o-')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "optimise_k_means(df.drop(['date','station_id'], axis = 1), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mencari jumlah n cluster optimal menggunakan silhouette method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah cluster: 2 | Silhouette Score: 0.3210568224689188\n",
      "Jumlah cluster: 3 | Silhouette Score: 0.29393191931925655\n",
      "Jumlah cluster: 4 | Silhouette Score: 0.3052004663881294\n",
      "Jumlah cluster: 5 | Silhouette Score: 0.2653099476032021\n",
      "Jumlah cluster: 6 | Silhouette Score: 0.283100503112427\n"
     ]
    }
   ],
   "source": [
    "# Menentukan rentang jumlah cluster yang akan diuji\n",
    "from sklearn.metrics import silhouette_score\n",
    "range_n_clusters = list(range(2, 7))\n",
    "\n",
    "# Menyimpan silhouette scores untuk setiap jumlah cluster\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X_pca, labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f'Jumlah cluster: {n_clusters} | Silhouette Score: {silhouette_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengaplikasikan model yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rave\\AppData\\Local\\Temp\\ipykernel_27024\\3713045052.py:32: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df['KMeans_Cluster'] = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "df['DBSCAN_Cluster'] = dbscan.fit_predict(X_pca)\n",
    "\n",
    "# Spectral Clustering\n",
    "spectral = SpectralClustering(n_clusters=4, affinity='nearest_neighbors', random_state=42)\n",
    "df['Spectral_Cluster'] = spectral.fit_predict(X_pca)\n",
    "\n",
    "# Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "df['GMM_Cluster'] = gmm.fit_predict(X_pca)\n",
    "\n",
    "# Plotting fungsi\n",
    "def plot_3d(X, labels, title):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=labels, cmap='viridis')\n",
    "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "    ax.add_artist(legend1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PCA Component 1')\n",
    "    ax.set_ylabel('PCA Component 2')\n",
    "    ax.set_zlabel('PCA Component 3')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting hasil clustering\n",
    "plot_3d(X_pca, df['KMeans_Cluster'], 'KMeans Clustering')\n",
    "plot_3d(X_pca, df['DBSCAN_Cluster'], 'DBSCAN Clustering')\n",
    "plot_3d(X_pca, df['Spectral_Cluster'], 'Spectral Clustering')\n",
    "plot_3d(X_pca, df['GMM_Cluster'], 'Gaussian Mixture Model Clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan evaluasi kinerja model menggunakan silhouette score, davies bouldin score, dan calinski harabarz score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Clustering:\n",
      "Silhouette Score: 0.305\n",
      "Davies-Bouldin Index: 1.052\n",
      "Calinski-Harabasz Index: 15492.785\n",
      "---------------------------------\n",
      "DBSCAN Clustering:\n",
      "Silhouette Score: -0.064\n",
      "Davies-Bouldin Index: 1.844\n",
      "Calinski-Harabasz Index: 6.449\n",
      "---------------------------------\n",
      "Spectral Clustering:\n",
      "Silhouette Score: 0.302\n",
      "Davies-Bouldin Index: 1.081\n",
      "Calinski-Harabasz Index: 15200.630\n",
      "---------------------------------\n",
      "GMM Clustering:\n",
      "Silhouette Score: 0.285\n",
      "Davies-Bouldin Index: 1.056\n",
      "Calinski-Harabasz Index: 14010.577\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Evaluasi clustering\n",
    "def evaluate_clustering(X, labels, method_name):\n",
    "    # Pastikan semua label adalah numerik\n",
    "    unique_labels = np.unique(labels)\n",
    "    if len(unique_labels) > 1:\n",
    "        silhouette_avg = silhouette_score(X, labels)\n",
    "        davies_bouldin_avg = davies_bouldin_score(X, labels)\n",
    "        calinski_harabasz_avg = calinski_harabasz_score(X, labels)\n",
    "        print(f'{method_name} Clustering:')\n",
    "        print(f'Silhouette Score: {silhouette_avg:.3f}')\n",
    "        print(f'Davies-Bouldin Index: {davies_bouldin_avg:.3f}')\n",
    "        print(f'Calinski-Harabasz Index: {calinski_harabasz_avg:.3f}')\n",
    "    else:\n",
    "        print(f'{method_name} Clustering: Only one cluster found')\n",
    "    print('---------------------------------')\n",
    "\n",
    "evaluate_clustering(X_pca, df['KMeans_Cluster'], 'KMeans')\n",
    "evaluate_clustering(X_pca, df['DBSCAN_Cluster'], 'DBSCAN')\n",
    "evaluate_clustering(X_pca, df['Spectral_Cluster'], 'Spectral')\n",
    "evaluate_clustering(X_pca, df['GMM_Cluster'], 'GMM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
